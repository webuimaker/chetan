---
title: "Bootstrapping in Statistics : Difference between Parametric and Nonparametric Bootstrap method"
author: Chetan Prajapati
date: '2020-04-12'
authorPos: Founder & Statistician at ISCON

description: This article explains the bootstrap method using example  using loops and boot function. Bootstrapping is a resampling method which used the Monte Carlo technique to estimate standard error, confidence interval, bias. The methods include parametric and non-parametric bootstrap

image: images/learnstatistics/bootstrap_in_R.png
alt: "bootstrap my alt"
categories: 
- Basic Statistics
slug: bootstrap-resampling-parametric-nonparametric-boot-how-to
subHeader: This article explains the bootstrap method using simple examples with help of loops and boot function in R. Bootstrapping is a resampling method which uses the Monte Carlo simulation to estimate standard error, confidence interval, bias. The difference between parametric and non-parametric bootstrap is also outlined

tags:
- Parametric Bootstrap
- Non-parametric Bootstrap

authorImage: images/about/chetan_statistician_UK.svg
type: learn-statistics
---



<p>This article explains bootstrap concept as a whole and discern the fundamental difference between parametric and nonparametric bootstrap using R. We will be using both-<code>for</code> loops and standard <code>boot</code> package</p>
<p><strong>Table of Contents </strong></p>
<ul>
<li><a href="#fundamental-of-statistical-inference">Fundamental of statistical inference</a></li>
<li><a href="#bootstrapping">Bootstrapping</a></li>
<li><a href="#nonparametric-bootstrap">Nonparametric bootstrap</a></li>
<li><a href="#parametric-bootstrap">Parametric Bootstrap</a></li>
</ul>
<div id="fundamental-of-statistical-inference" class="section level2">
<h2>Fundamental of statistical inference</h2>
<p>We first need to understand following some fundamental concepts. The idea behind bootstrapping is very closely aligned with those concepts.</p>
<p>Here I have created a hypothetical study in which we are interested in finding out the average birth weight of the babies born in the UK at 37 weeks of gestation.</p>
<ul>
<li><p><strong>Experiment </strong>: To find out the average weight of babies born at 37 weeks in the UK</p></li>
<li><p><strong>Random sample </strong>: Random sample means each and every single individual or object has an equal probability of being chosen from the population. For example, in our study, the population is all birth happened in the UK at 37 weeks of gestation. For typical “random sample”, we will need to make sure that each and every birth happening in any corner of the UK, will be participating in our study, from which will choose some of them randomly i.e random sample.</p></li>
<li><p><strong>Sample data</strong>: the recorded observation or quantity from the sample of the population. Now we have gone to one local hospital and got data of the birth-weights from 20 babies. Here is the (hypothetical) sample data.</p></li>
</ul>
<pre><code> [1] 3331.608 3549.913 2809.252 2671.465 3383.177 3945.721 3672.601 3922.416
 [9] 4647.278 4088.246 3718.874 3724.443 3925.457 3112.920 3495.621 3651.779
[17] 3240.194 3867.347 3431.015 4163.725</code></pre>
<ul>
<li><strong>Sample statistic </strong>: is the quantity of interest from sample data. The quantity of interest in our study is a mean (average). So mean is our sample statistic. So sample statistic in our sample data is <strong>3618</strong>,</li>
</ul>
<pre><code>[1] 3617.653</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-4"></span>
<img src="boot.png" alt="Parametric"  />
<p class="caption">
Figure 1: Parametric
</p>
</div>
<ul>
<li><strong>Sampling distribution (of statistic) </strong>: Now we went to take a random sample of 20 babies at numerous hospitals (i.e.multiple times) in the UK. Each time, we calculate the mean birth weight and note down its value. This value will be different in each different hospital (in a statistical sense, the statistic is a random variable, will vary as variation is inherent). Here we went to 100 hospitals and took a sample of 20 babies born at that hospital and calculated the mean birth weight and plotted in the histogram.</li>
</ul>
<pre class="r"><code>ggplot(data.frame(statistic), aes(statistic)) + geom_histogram() + labs(x= &quot;Mean&quot;, y= &quot;Freqency&quot;) + theme_ISCON()

binw &lt;- 2*(IQR(statistic)/length(statistic)^(1/3))
ggplot(data.frame(statistic), aes(statistic)) + geom_histogram(aes(y=..density..),binwidth = binw,fill=&quot;#cf0300&quot;,colour=&quot;white&quot;) + geom_density(aes(y=..density..),size=0.5) + labs(x= &quot;Mean&quot;, y= &quot;Density&quot;)  + theme_ISCON()</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-6"></span>
<img src="/learn-statistics/bootstrapping/index.en_files/figure-html/unnamed-chunk-6-1.svg" alt="Default histogram (left) and histogram with proper binwidth(right)" width="50%" /><img src="/learn-statistics/bootstrapping/index.en_files/figure-html/unnamed-chunk-6-2.svg" alt="Default histogram (left) and histogram with proper binwidth(right)" width="50%" />
<p class="caption">
Figure 2: Default histogram (left) and histogram with proper binwidth(right)
</p>
</div>
<p>It is better to plot the histogram with optimum bin width (see <a href="https://link.springer.com/article/10.1007/BF01025868">Article from David Freedman</a>) along with density curve using <code>aes(y=..density..)</code>.So that the area under the density curve will be 1</p>
<ul>
<li><p><strong>Population parameter </strong>: What will be the mean birth-weight of babies born in the UK if we had gone on collecting birthright of each and every single baby born in the UK. This will be only one value that what we are basically interested in. This is called the population parameter. The problem is that we want to estimate that from our limited number of observations (i.e sample data). The sample statistic will help to estimate the population parameter. The sample statistic will also be called point estimator.</p></li>
<li><p><strong>Standard error(of statistic)</strong> is the standard deviation (SD) of statistic from its sampling distribution. Note that SD is a statistic that measures the variability in data relative to its mean.</p></li>
<li><p><strong>Confidence interval </strong>: Though we are interested in population parameter i.e single value, what if our sample data may not contain it. We need to provide some measure of it. This can be achieved by building a confidence interval. We can say that the true value of the population lies in some interval with some degree of confidence.</p></li>
</ul>
<p>So, in essence, we want to estimate a population parameter from the sampling distribution of the sample statistic. This sampling distribution can be generated by infinite time random sampling.</p>
</div>
<div id="bootstrapping" class="section level2">
<h2>Bootstrapping</h2>
<p>The bootstrap method is one type of re-sampling method, in which sample data (20 birth weights) considered as “population”.From this sample data, we re-sample it with a replacement-large number of time (the 1000’s). The resultant sampling distribution often (not always) approximate the (true) sampling distribution of the statistic.</p>
<p>Please note, that this sampling will be done with the replacement. So some single observation may be included many times ( or some may be left out completely). So sample statistic will be varied from each random sample of size n.</p>
<p>From this bootstrapped sampling distribution, which can estimate parameter value, standard errors (standard deviation of sample statistic) and then, calculate the confidence interval.</p>
<p>Let,</p>
<ul>
<li><p><strong><span class="math inline">\(\theta\)</span></strong> is population parameter of interest which belongs to unknown population distribution <strong>F</strong></p></li>
<li><p><strong><span class="math inline">\(\hat{\theta}\)</span></strong> is statistic that estimate the <span class="math inline">\(\theta\)</span> and we are interests in sampling distribution of <strong><span class="math inline">\(\hat{\theta}\)</span></strong> from fitted distribution function <strong><span class="math inline">\(\hat{F}\)</span></strong></p></li>
<li><p><span class="math inline">\(\hat{\theta_0^*}\)</span>,<span class="math inline">\(\hat{\theta_1^*}\)</span>,<span class="math inline">\(\hat{\theta_2^*}\)</span>… bootstrap estimate (statistic) to obtain sampling distribution of <strong><span class="math inline">\(\hat{\theta^*}\)</span></strong> is <strong><span class="math inline">\(\hat{F^*}\)</span></strong>. This sampling distribution is good approximation of <strong><span class="math inline">\(\hat{F}\)</span></strong></p></li>
</ul>
</div>
<div id="nonparametric-bootstrap" class="section level2">
<h2>Nonparametric bootstrap</h2>
<p>We observed the sample data and we are unable to determine from which probability distribution function may have generated this sample data. In this situation, we use empirical distribution function (which is based on observed sample data) to simulate bootstrap samples (using Monte Carlo techniques).</p>
<pre class="r"><code># loop
theta_star &lt;- vector()
for (i in 1:1000){
  theta_star[i] &lt;- mean(sample(df,size=length(df),replace = T))
  # First take sample with replacement from obseerved data of same size &amp; then, calculte sample statistic in each, repeat this 1000 times
}</code></pre>
<pre class="r"><code>theta_boot &lt;- mean(theta_star) # bootstrap estimate of theta_hat
theta_boot</code></pre>
<pre><code>[1] 3616.166</code></pre>
<pre class="r"><code>boot_se &lt;- sd(theta_star) # standard eorrs of the estimate
boot_se</code></pre>
<pre><code>[1] 102.6719</code></pre>
<pre class="r"><code>bias &lt;- theta_boot - mean(df)
bias</code></pre>
<pre><code>[1] -1.487018</code></pre>
<pre class="r"><code>MSE &lt;- mean((theta_boot- mean(df))^2)
MSE</code></pre>
<pre><code>[1] 2.211222</code></pre>
<pre class="r"><code>CI &lt;-c(theta_boot-1.96*boot_se,theta_boot +1.96*boot_se)
CI</code></pre>
<pre><code>[1] 3414.929 3817.402</code></pre>
<p>We can use a <code>boot</code> function from the <code>boot</code> package in R.It requires a function to calculate sample statistic ( in its <code>statistic</code> argument). The function must include observed data as the first argument and indices ( or weight) in the second argument.</p>
<pre class="r"><code>require(boot)
theta_star_function &lt;- function(x,i) mean(x[i])
#
B &lt;- boot(data = df, statistic = theta_star_function, R=1000, stype = &quot;i&quot; )
B</code></pre>
<pre><code>
ORDINARY NONPARAMETRIC BOOTSTRAP


Call:
boot(data = df, statistic = theta_star_function, R = 1000, stype = &quot;i&quot;)


Bootstrap Statistics :
    original    bias    std. error
t1* 3617.653 0.9443187    98.78257</code></pre>
<p>We can used default plots to see whether bootstrap samples are correctly sampled.</p>
<pre class="r"><code>plot(B)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-15"></span>
<img src="/learn-statistics/bootstrapping/index.en_files/figure-html/unnamed-chunk-15-1.svg" alt="Bootstrap sampling distribution of sample mean" width="672" />
<p class="caption">
Figure 3: Bootstrap sampling distribution of sample mean
</p>
</div>
<p>Or, one can use <code>ggplot</code> to get the same figure</p>
<pre class="r"><code>binw &lt;- 2*(IQR(B$t)/length(B$t)^(1/3))
ggplot(data.frame(B$t), aes(B.t)) + geom_histogram(fill=&quot;grey&quot;, colour=&quot;black&quot;, binwidth = binw) + geom_vline(xintercept = B$t0, linetype=&quot;dashed&quot;, size=1) + labs(x=&quot;Bootstrap sample statistic&quot;, title=&quot;Bootstrap sampling distribution of sample mean&quot;)  + theme_ISCON()</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-16"></span>
<img src="/learn-statistics/bootstrapping/index.en_files/figure-html/unnamed-chunk-16-1.svg" alt="Bootstrap sampling distribution of sample mean  (ggplot2)" width="672" />
<p class="caption">
Figure 4: Bootstrap sampling distribution of sample mean (ggplot2)
</p>
</div>
<p>We can get confidence interval by,</p>
<pre class="r"><code>boot.ci(B)</code></pre>
<pre><code>BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 1000 bootstrap replicates

CALL : 
boot.ci(boot.out = B)

Intervals : 
Level      Normal              Basic         
95%   (3423, 3810 )   (3421, 3819 )  

Level     Percentile            BCa          
95%   (3416, 3814 )   (3407, 3804 )  
Calculations and Intervals on Original Scale</code></pre>
</div>
<div id="parametric-bootstrap" class="section level2">
<h2>Parametric Bootstrap</h2>
<p>Once we have a sample data, we may think that the observed data may have come from some known probability distribution function ( i.e normal, gamma or poisson or any).</p>
<p>For example in our sample birth weights, we may assume that observed birth-weight comes from normal distribution with parameter <span class="math inline">\(\mu\)</span> = 3617.7 and <span class="math inline">\(\sigma\)</span> = 464.6 ( which is estimated from observed data). See the below figure,</p>
<pre class="r"><code>ggplot(data.frame(df), aes(df)) + geom_density() + labs(x= &quot;birth weight&quot;)  + theme_ISCON()</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-18"></span>
<img src="/learn-statistics/bootstrapping/index.en_files/figure-html/unnamed-chunk-18-1.svg" alt="Distribution of observed sample birthweights" width="672" alt = "my alt" />
<p class="caption">
Figure 5: Distribution of observed sample birthweights
</p>
</div>
<p>So, instead of using observed data ( as a non-parametric bootstrap), we can use normal distribution function with probable parameter estimates ( which most likely the maximum likelihood estimates) for bootstrap re-sampling.</p>
<p>Let, first do it with help of <code>for</code> loops in R.</p>
<pre class="r"><code>theta_star &lt;- vector()
for (i in 1:1000){
  theta_star[i] &lt;- mean(rnorm(length(df),mean = 3617.7 ,sd = 464.6))
}</code></pre>
<pre class="r"><code>theta_boot &lt;- mean(theta_star) # bootstrap estimate of theta_hat
theta_boot</code></pre>
<pre><code>[1] 3613.883</code></pre>
<pre class="r"><code>boot_se &lt;- sd(theta_star) # standard eorrs of the estimate
boot_se</code></pre>
<pre><code>[1] 101.4233</code></pre>
<pre class="r"><code>bias &lt;- theta_boot - mean(df)
bias</code></pre>
<pre><code>[1] -3.769489</code></pre>
<pre class="r"><code>MSE &lt;- mean((theta_boot- mean(df))^2)
MSE</code></pre>
<pre><code>[1] 14.20905</code></pre>
<pre class="r"><code>CI &lt;-c(theta_boot-1.96*boot_se,theta_boot +1.96*boot_se)
CI</code></pre>
<pre><code>[1] 3415.094 3812.673</code></pre>
<p>Now, using <code>boot</code> function,</p>
<p>For parametric bootstrap, one has to specify a function in <code>ran.gen</code> arguments, which tell the boots how random sample will be generated ( I mean, from which distribution, parameters you want to generate re-sample). The first argument will be the observed data and the second argument will be parameter estimates.This function should give random samples according to your assumed distribution function.</p>
<pre class="r"><code>gen_function &lt;- function(x,mle) {
  data &lt;- rnorm(length(x),mle[1],mle[2])
  return(data)}</code></pre>
<pre class="r"><code># function to calculate sample statistic 
theta_star_function &lt;- function(x,i) mean(x[i])</code></pre>
<p>The <code>mle</code> values ( of parameter estimates ) passed to random generator function.</p>
<pre class="r"><code>B &lt;- boot(data = df, sim = &quot;parametric&quot;, ran.gen =  gen_function, mle = c(3617.7,464.6), statistic = theta_star_function, R=1000)
B</code></pre>
<pre><code>
PARAMETRIC BOOTSTRAP


Call:
boot(data = df, statistic = theta_star_function, R = 1000, sim = &quot;parametric&quot;, 
    ran.gen = gen_function, mle = c(3617.7, 464.6))


Bootstrap Statistics :
    original     bias    std. error
t1* 3617.653 0.05774845    101.8872</code></pre>
<pre class="r"><code>plot(B)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-28"></span>
<img src="/learn-statistics/bootstrapping/index.en_files/figure-html/unnamed-chunk-28-1.svg" alt="Parametric bootstrap using boot package" width="672" />
<p class="caption">
Figure 6: Parametric bootstrap using boot package
</p>
</div>
<pre class="r"><code>boot.ci(B,type = &quot;perc&quot;)</code></pre>
<pre><code>BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 1000 bootstrap replicates

CALL : 
boot.ci(boot.out = B, type = &quot;perc&quot;)

Intervals : 
Level     Percentile     
95%   (3413, 3813 )  
Calculations and Intervals on Original Scale</code></pre>
</div>
